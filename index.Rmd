---
title: "Wine Data Machine Learning Models"
author: "Cole Maxwell, Hoomz Damte, and Noah Constable"
date: "4/29/2022"
output:
  html_document: default
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
```

These data were obtained from the University of California Irvine's (UCI) [Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/wine). These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. These models attempt to determine the `quality` of both white and red wines, and predict the `Type` of wine (White or Red).

# Data Pre-Processing 

The data are loaded into r data frames from the `.csv` files obtained from the UCI Machine Learning Repository. There are two files that are separated by red and white types of wine. Once each file is loaded as a data frame, `rbind` is used to combine the two data frames into one larger frame that can be used for the machine learning models.

```{r, style="display: flex;"}
library(keras)
library(tensorflow)
library(ggplot2)

# Loading wine csv files
WhiteWineQualityDataFrame <- read.csv("winequality-white.csv", sep = ";")
RedWineQualityDataFrame <- read.csv("winequality-red.csv", sep = ";")

# Combine the two data frames
WineQualityDataFrame <- rbind(WhiteWineQualityDataFrame, RedWineQualityDataFrame)

```
The variables and their types:
```{r}
str(WineQualityDataFrame) 
```


Summary statistics of each variable in the data frame:
```{r}
summary(WineQualityDataFrame)
```


\clearpage

## Exploritory Analysis 

To determinate if there is any clear pattern or relationship in these data a heatmap of the correlation between quality and each variable can be used. Darker (or more red) colors indicate higher correlation between two variables.
```{r}
# Evaluation of the correlation variables
WineQualityMatrix <- data.matrix(WineQualityDataFrame)
WineQualityCorrelation <- cor(WineQualityMatrix)

# Generate a heatmap of correlations
heatmap(WineQualityCorrelation, 
        margins = c(8, 8), 
        main = "Vaiable Correspondence with Quality",
        )
```

There does not seem to be any clear pattern from this heatmap, and all variables look like they be highly interconnected. There is no clear variable that should be removed to lower the complexity of the initial model. 

\clearpage

Next the frequency of each quality level should be evaluated. Since quality is the variable that the machine learning model should predict, each level should be "balanced" or have roughly equal observations at each level to ensure that the machine learning model can produce an accurate model. 

```{r}
table(WineQualityDataFrame$quality) %>%
  kable(col.names = c("Quality Level", "Frequency"))

hist(WineQualityDataFrame$quality, 
     xlab = "Quality",
     main = "Frequency of Each Quality Catagory"
     )
```

From the frequency table and histogram there is a clear imbalance in these data. The `quality` levels 2, 3, and 4 are over represented in these data. If this imbalance in the data is not corrected it causes the performance of existing classifiers to become biased towards majority class. Machine learning algorithms also assume that the data set has balanced class distributions.

## Dealing With Imbalanced Classification

Sampling Methods can be used to modify an imbalanced data into balanced distribution using several different mechanisms:

1. Under-sampling
2. Over-sampling
3. Synthetic Data Generation
4. Cost Sensitive Learning

The ROSE (Random Over Sampling Examples) package helps to generate artificial data based on sampling methods and smoothed bootstrap approach. This package has well defined accuracy functions to do the tasks quickly.

We attempted to use this package for these data. However, we found that ROSE requires the response variable to only contain two factors. Had this worked correctly, the majority classes would have been under-sampled to around 1000 observations. At the same time, the minority classes would have had observations added via synthetic data generation algorithm to around 1000 observations per level. 

```{r, eval=F}
# This Code is not used by our analysis 
library(ROSE)

# Store quality as a factor
WineQualityDataFrame$quality <- as.lev(WineQualityDataFrame$quality)

# Undersample and Synthetic Data Generation on factors
data_balanced_both <- ovun.sample(quality ~ ., data = WineQualityDataFrame, method = "both", p=0.5, N=1000, seed = 1)$data

```

Instead, we manually over-sampled and under-sampled each level of quality. Levels 3,4,8, and 9 required the over-sampling technique. These quality levels contained less than 1000 observations, which is an arbitrary threshold that we decided each quality level should be. To over-sample we selected all of the observations in 3-4 and 8-9, the duplicated them until each level contain about 1000 observations.
```{r}
# Extract rows where quality is level 3 and repeat until about 1000 rows (Over Sampling)
quality3 <- WineQualityDataFrame[which( WineQualityDataFrame$quality == 3 ), ]
quality3 <- do.call("rbind", replicate(33, quality3, simplify = FALSE))

# Extract rows where quality is level 4 and repeat until about 1000 rows (Over Sampling)
quality4 <- WineQualityDataFrame[ which(WineQualityDataFrame$quality == 4) , ]
quality4 <- do.call("rbind", replicate(5, quality4, simplify = FALSE))

# Extract rows where quality is level 8 and repeat until about 1000 rows (Over Sampling)
quality8 <- WineQualityDataFrame[ which(WineQualityDataFrame$quality == 8) , ]
quality8 <- do.call("rbind", replicate(5, quality8, simplify = FALSE))

# Extract rows where quality is level 9 and repeat until about 1000 rows (Over Sampling)
quality9 <- WineQualityDataFrame[ which(WineQualityDataFrame$quality == 9) , ]
quality9 <- do.call("rbind", replicate(200, quality9, simplify = FALSE))
```

Quality levels 5-7 required the under-sampling technique. These levels contained more than 1000 observations. The `sample()` function is used to select 1000 random observations from each level.
```{r}
# Random sample of 1000 from levels 5-7 (Under-Sampling)
quality5 <- WineQualityDataFrame[ sample( which( WineQualityDataFrame$quality == 5 ) , 1000 ) , ]
quality6 <- WineQualityDataFrame[ sample( which( WineQualityDataFrame$quality == 6 ) , 1000 ) , ]
quality7 <- WineQualityDataFrame[ sample( which( WineQualityDataFrame$quality == 7 ) , 1000 ) , ]
```

Then each data frame is combined together and reassigned to the `WineQualityDataFrame` data frame
```{r}
WineQualityDataFrame <-rbind(quality3,
                              quality4,
                              quality5,
                              quality6,
                              quality7,
                              quality8,
                              quality9)
```

Now the frequency of each `quality` level has about 1000 observations: 
```{r}
table(WineQualityDataFrame$quality) %>% 
  kable(col.names = c("Quality Level", "Frequency"))

hist(WineQualityDataFrame$quality, 
     xlab = "Quality",
     main = "Frequency of Each Quality Catagory"
     )
```

\clearpage

## Generating Training and Testing Data Sets

To get training data a random sample of 80% of the balanced data is assigned to a new data frame `picked`. To generate the `training` data frame `picked` are selected from `WineQualityDataFrame`. The testing data is generated by removing `picked` from `WineQualityDataFrame`.

Then one-hot encoding is preformed on the quality variable in the `training` and `testing` data frames. In order for one hot encoding to work correctly the levels of quality must start at 0. To do this we simply subtract three from the `quality` column before splitting the data into testing and training sets

```{r}
# Get 80% of the rows from the data set 
sampleSize <- round(nrow(WineQualityDataFrame) * 0.8)

# setting random seed to make results repeatable
set.seed(1234) 


# Subtract three from the quality column so quality levels start at zero
WineQualityDataFrame$quality <- WineQualityDataFrame$quality -3

# Picking a random sample equal to the sample size
picked <- sample(seq_len(nrow(WineQualityDataFrame)),size = sampleSize)

# Separate data into training and testing sets
training <- WineQualityDataFrame[picked,]
testing <- WineQualityDataFrame[-picked,]


# Changing y into categorical data (performing one-hot encoding)
yTr <- to_categorical(training$quality, num_classes = 7)
yTest <- to_categorical(testing$quality, num_classes = 7)

```

# Neural Network for Wine Quality

This model used the `categorical_crossentropy` loss function to try to predict each category of wine quality. Since we are using all the features of these data the input shape is set to 11. We found that four hidden layers each with 96 units produced the best results. 100 epochs yielded the highest accuracy with the least model over fitting.

Other things we tried:

* Increased epochs to 100
* Increased epochs to 1000, severely over fit
* Decreased epochs to 300, severely over fit
* Increased units from 96 to 128 in first layer, severely over fit
* Increased hidden layer to 5 and 6, severely over fit 
* Added dropout of 20%, severely decreased accuracy

### Without Regularization

The first model contains no regularization on any hidden layer.
```{r, eval=T, results='hide'}

wineModel = keras_model_sequential() %>%
  layer_dense(units = 96, activation = "relu",input_shape=(11)) %>%
  layer_dense(units = 96, activation = "relu") %>%
  layer_dense(units = 96, activation = "relu") %>%
  layer_dense(units = 96, activation = "relu") %>%
  layer_dense(units = ncol(yTr), activation = "softmax")


wineModel %>% compile(
  loss = "categorical_crossentropy",
  optimizer = "adam", #optimizer_rmsprop(),
  metrics = "accuracy"
)

xTr <- as.matrix(training[,1:11]) # need to convert to a matrix
xTest <- as.matrix(testing[,1:11])

history <- wineModel %>% 
  fit(
    x = xTr, # input is the first 4 columns of the dataframe
    y = yTr, # label is the last column
    epochs = 100
  )

```

#### Model Evaluation

This model classifies wine quality correctly about 70-74% of the time. However, the model is overfitting these data.
```{r, eval=T}
plot(history)
summary(wineModel)
wineModel %>% evaluate(xTest, yTest)
```


### With L2 Regularization

Now L2 regularization is added to each hidden layer. L2 regularization can deal with the multicollinearity (independent variables are highly correlated) problems through constricting the coefficient and by keeping all the variables. This fits to our data best so we used this type of regularization. L2 regression can be used to estimate the significance of predictors and based on that it can penalize the insignificant predictors.
```{r, results='hide' , eval=T}

wineModel = keras_model_sequential() %>%
  layer_dense(units = 96, activation = "relu",input_shape=(11), regularizer_l2(l = 0.01)) %>%
  layer_dense(units = 96, activation = "relu", regularizer_l2(l = 0.01)) %>%
  layer_dense(units = 96, activation = "relu", regularizer_l2(l = 0.01)) %>%
  layer_dense(units = 96, activation = "relu", regularizer_l2(l = 0.01)) %>%
  layer_dense(units = ncol(yTr), activation = "softmax")


wineModel %>% compile(
  loss = "categorical_crossentropy",
  optimizer = "adam", #optimizer_rmsprop(),
  metrics = "accuracy"
)

xTr <- as.matrix(training[,1:11]) # need to convert to a matrix
xTest <- as.matrix(testing[,1:11])

history <- wineModel %>% 
  fit(
    x = xTr, # input is the first 4 columns of the dataframe
    y = yTr, # label is the last column
    epochs = 100
  )

```
#### Model Evaluation

This model is classifies wine quality correctly about 70-74% of the time. So, L2 regularization gives mixed and inconsistent results, but typically reduces the model overfitting.
```{r, eval=T}
plot(history)
summary(wineModel)
wineModel %>% evaluate(xTest, yTest)
```

# Red and White Wine Classification

Next, we tried to see of we could predict the type of wine (Red or White) based on the same variables on the data. To start, a binary classification variable of `Type` is added to the data to indicate whether a wine belongs to the red or white class. This will be used to do binary cross entropy for the machine learning model. The `quality` column is also dropped because we do not want to use quality as a predictor of wine type.

```{r}
#Loading a csv file
WhiteWineQualityDataFrame <- read.csv("winequality-white.csv", sep = ";")
WhiteWineQualityDataFrame["Type"] <- 0
RedWineQualityDataFrame <- read.csv("winequality-red.csv", sep = ";")
RedWineQualityDataFrame ["Type"] <- 1
WineQualityDataFrame <- rbind(WhiteWineQualityDataFrame, RedWineQualityDataFrame)

WineQualityDataFrame <- subset(WineQualityDataFrame, select = -c(quality))

```


## Exploritory Analysis

There is a similar class in balance problem as the prior data set had. White wine is severely over represented and is the majority class in these data.

```{r}
table(WineQualityDataFrame$Type) %>% 
  kable(col.names = c("Type Level", "Frequency"),
        )
```

To solve this imbalance in the classes we used under-sampling to take a large simple random sample to balance the classes. Since there are just over 1500 observations in the white wine class, 1500 is the sample size used to retain as many observations as possible while still using the under-sampling technique. 

```{r}
red <- WineQualityDataFrame[ sample( which( WineQualityDataFrame$Type == 1 ) , 1500 ) , ]
white <- WineQualityDataFrame[ sample( which( WineQualityDataFrame$Type == 0 ) , 1500 ) , ]

underSampledWine <- rbind(red, white)


table(underSampledWine$Type) %>% 
  kable(col.names = c("Type Level", "Frequency"),
        )
```

## Generating Training and Testing Data Sets

To get training data a random sample of 80% of the balanced data is assigned to a new data frame `picked`. To generate the `training` data frame `picked` are selected from `WineQualityDataFrame`. The testing data is generated by removing `picked` from `WineQualityDataFrame`.

Then one-hot encoding is preformed on the quality variable in the `training` and `testing` data frames. Since the `Type` variable is already in a binary format it can be one-hot encoded without any manipulation. 

```{r}

sample_size <- round(nrow(underSampledWine) * 0.8)
set.seed(1234) # setting random seed to make results repeatable

picked <- sample(seq_len(nrow(underSampledWine)),size = sample_size)
training <- underSampledWine[picked,]
testing <- underSampledWine[-picked,]


# Changing y into categorical data (performing one-hot encoding)

yTr <- to_categorical(training$Type, num_classes = 2)
yTest <- to_categorical(testing$Type, num_classes = 2)

```

## Model

This model uses the `binary_crossentropy` loss function to predict the `Type` of wine. Since we are using all the features of these data the input shape is set to 11. We found that four hidden layers each with 32 units produced the best results. 50 epochs yielded the highest accuracy with the least model over fitting. We also found that adding regularization to this model did not improve the accuracy.

```{r, results='hide', eval=T}

wineModel = keras_model_sequential() %>%
  layer_dense(units = 32, activation = "relu",input_shape=(11)) %>%
  layer_dense(units = 32, activation = "relu") %>%
  layer_dense(units = 32, activation = "relu") %>%
  layer_dense(units = 32, activation = "relu") %>%
  layer_dense(units = ncol(yTr), activation = "softmax")


wineModel %>% compile(
  loss = "binary_crossentropy",
  optimizer = "adam", #optimizer_rmsprop(),
  metrics = "accuracy"
)

xTr <- as.matrix(training[,1:11]) # need to convert to a matrix
xTest <- as.matrix(testing[,1:11])

history <- wineModel %>% 
  fit(
    x = xTr, # input is the first 4 columns of the dataframe
    y = yTr, # label is the last column
    epochs = 50
  )

```
#### Model Evaluation

This model can predict the type of wine based on these parameters with about 96% accuracy. 

```{r, eval=T}
plot(history)
summary(wineModel)
wineModel %>% evaluate(xTest, yTest)
```