---
title: "FinalProject"
author: "Cole Maxwell"
date: "4/18/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
library(keras)
library(tensorflow)


#Loading a csv file
WineQualityDataFrame <- read.csv("WineQT.csv")

WineQualityDataFrame <- subset(WineQualityDataFrame, select = -c(Id))

# Various syntax for R dataframes
summary(WineQualityDataFrame)

head(WineQualityDataFrame)

head(WineQualityDataFrame$quality)

```

## Splitting data into training and testing

```{r}
sample_size <- 120
set.seed(1234) # setting random seed to make results repeatable


# Subtract three to so quality levels start at zero
WineQualityDataFrame$quality <- WineQualityDataFrame$quality -3

picked <- sample(seq_len(nrow(WineQualityDataFrame)),size = sample_size)
training <- WineQualityDataFrame[picked,]
testing <- WineQualityDataFrame[-picked,]


# Changing y into categorical data (performing one-hot encoding)

yTr <- to_categorical(training$quality, num_classes = 6)
yTest <- to_categorical(testing$quality, num_classes = 6)

```

## Neural network for the iris example

This is where we tried to improve our accuracy. One way we found that was somewhat successful
was to increase the number of epochs. We think Elena chose 20 epochs because she had a smaller data
set but since ours was larger we needed more. We found that after 300 we got vastly diminishing
returns, so we settled on 300 for the time being. We are still looking at ways of improving accuracy.

initial accuracy -> ~43%
drop Id feature -> no improvement in accuracy
increase epochs to 100 -> accuracy raised to ~53%
increase epochs to 1000 -> accuracy raised to ~67%
decrease epochs to 300 -> accuracy lowered to ~60%
increase units from 64 to 128 in first layer -> ~56%
increase input_shape from 4 to 11 -> ~80%
increase first layer units from 64 to 128 -> ~81%
increase second layer units from 64 to 128 -> ~88%

```{r}

model = keras_model_sequential() %>%
  layer_dense(units = 128, activation = "relu",input_shape=(11)) %>%
  layer_dense(units = 128, activation = "relu") %>%
  layer_dropout(rate = 0.25) %>%
  layer_dense(units = 128, activation = "relu") %>%
  layer_dense(units = 128, activation = "relu") %>%
  layer_dense(units = 128, activation = "relu") %>%
  layer_dropout(rate = 0.25) %>%
  layer_dense(units = ncol(yTr), activation = "softmax")


model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = "adam", #optimizer_rmsprop(),
  metrics = "accuracy"
)

xTr <- as.matrix(training[,1:11]) # need to convert to a matrix
xTest <- as.matrix(testing[,1:11])

model %>% 
  fit(
    x = xTr, # input is the first 4 columns of the dataframe
    y = yTr, # label is the last column
    epochs = 300
  )

```

# Evaluate the model
```{r}
model %>% evaluate(xTest, yTest)

# Predicting likelihood of all categories:
result <- model %>% predict(xTest)

result

testing[,5]

```
